{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35\n",
      "Precision: 0.35\n",
      "Recall: 1.0\n",
      "F1 Score: 0.5185185185185185\n",
      "ROC AUC Score: 0.5\n",
      "Confusion Matrix:\n",
      " [[ 0 52]\n",
      " [ 0 28]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "class SVM:\n",
    "    def __init__(self, C=1.0, max_iter=100, kernel='linear'):\n",
    "        self.C = C  # Regularization parameter\n",
    "        self.max_iter = max_iter  # Maximum number of iterations\n",
    "        self.kernel = kernel  # Kernel function ('linear' or 'rbf')\n",
    "        self.kernel_func = self._linear_kernel if kernel == 'linear' else self._rbf_kernel\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X  # Store training data\n",
    "        self.y_train = y  # Store training labels\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self.alpha = np.zeros(n_samples)\n",
    "        self.b = 0\n",
    "        \n",
    "        # Precompute kernel matrix\n",
    "        self.K = np.zeros((n_samples, n_samples))\n",
    "        for i in range(n_samples):\n",
    "            self.K[i] = self.kernel_func(X[i], X)\n",
    "        \n",
    "        # Training\n",
    "        for _ in range(self.max_iter):\n",
    "            for i in range(n_samples):\n",
    "                # Pick random sample (i1) and compute prediction\n",
    "                i1 = self._random_selection(i, n_samples)\n",
    "                y_pred_i1 = self._predict(X[i1])\n",
    "                \n",
    "                # Compute error\n",
    "                Ei1 = y_pred_i1 - y[i1]\n",
    "                \n",
    "                # Pick second sample (i2) using heuristics\n",
    "                i2 = self._heuristic_selection(Ei1, i, n_samples)\n",
    "                \n",
    "                # Compute predictions\n",
    "                y_pred_i2 = self._predict(X[i2])\n",
    "                Ei2 = y_pred_i2 - y[i2]\n",
    "                \n",
    "                # Save old alphas\n",
    "                alpha_i1_old = self.alpha[i1]\n",
    "                alpha_i2_old = self.alpha[i2]\n",
    "                \n",
    "                # Compute L and H\n",
    "                if y[i1] != y[i2]:\n",
    "                    L = max(0, self.alpha[i2] - self.alpha[i1])\n",
    "                    H = min(self.C, self.C + self.alpha[i2] - self.alpha[i1])\n",
    "                else:\n",
    "                    L = max(0, self.alpha[i1] + self.alpha[i2] - self.C)\n",
    "                    H = min(self.C, self.alpha[i1] + self.alpha[i2])\n",
    "                \n",
    "                # Update alpha i2\n",
    "                self.alpha[i2] = alpha_i2_old + y[i2] * (Ei1 - Ei2) / (self.K[i1, i1] + self.K[i2, i2] - 2 * self.K[i1, i2])\n",
    "                \n",
    "                # Clip alpha i2\n",
    "                self.alpha[i2] = max(L, min(H, self.alpha[i2]))\n",
    "                \n",
    "                # Update alpha i1\n",
    "                self.alpha[i1] = alpha_i1_old + y[i1] * y[i2] * (alpha_i2_old - self.alpha[i2])\n",
    "                \n",
    "                # Update threshold b\n",
    "                b1 = self.b - Ei1 - y[i1] * (self.alpha[i1] - alpha_i1_old) * self.K[i1, i1] - y[i2] * (self.alpha[i2] - alpha_i2_old) * self.K[i1, i2]\n",
    "                b2 = self.b - Ei2 - y[i1] * (self.alpha[i1] - alpha_i1_old) * self.K[i1, i2] - y[i2] * (self.alpha[i2] - alpha_i2_old) * self.K[i2, i2]\n",
    "                \n",
    "                if 0 < self.alpha[i1] < self.C:\n",
    "                    self.b = b1\n",
    "                elif 0 < self.alpha[i2] < self.C:\n",
    "                    self.b = b2\n",
    "                else:\n",
    "                    self.b = (b1 + b2) / 2\n",
    "    \n",
    "    def _predict(self, X):\n",
    "        return np.sign(np.sum(self.alpha * self.kernel_func(X, self.X_train)) + self.b)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict(x) for x in X])\n",
    "    \n",
    "    def _linear_kernel(self, x1, x2):\n",
    "        return np.dot(x1, x2.T)\n",
    "    \n",
    "    def _rbf_kernel(self, x1, x2, gamma=0.1):\n",
    "        return np.exp(-gamma * np.linalg.norm(x1 - x2) ** 2)\n",
    "    \n",
    "    def _random_selection(self, i, n_samples):\n",
    "        i1 = i\n",
    "        while i1 == i:\n",
    "            i1 = np.random.randint(n_samples)\n",
    "        return i1\n",
    "    \n",
    "    def _heuristic_selection(self, Ei1, i, n_samples):\n",
    "        i2 = -1\n",
    "        max_delta_error = 0\n",
    "        for j in range(n_samples):\n",
    "            if j != i:\n",
    "                Ej = self._predict(self.X_train[j]) - self.y_train[j]\n",
    "                delta_error = abs(Ei1 - Ej)\n",
    "                if delta_error > max_delta_error:\n",
    "                    i2 = j\n",
    "                    max_delta_error = delta_error\n",
    "        if i2 == -1:  # if i2 is not updated, choose randomly\n",
    "            i2 = self._random_selection(i, n_samples)\n",
    "        return i2\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"Social_Network_Ads.csv\")\n",
    "one = LabelEncoder()\n",
    "data['Gender'] = one.fit_transform(data['Gender'])\n",
    "# Separate features and target variable\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train SVM\n",
    "svm = SVM(C=1.0, max_iter=100, kernel='rbf')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
